{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pattern import web\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import doctest\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPages(url):\n",
    "    '''\n",
    "    Function\n",
    "    --------\n",
    "    Returns the page range of the query\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url: str\n",
    "        First page of the British Museum query\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple containing the first page and the last \n",
    "    page numbers, respectively.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    For \"http://www.britishmuseum.org/research/collection_online/search.aspx?searchText=augustus\"\n",
    "    it would return (1, 474)\n",
    "    \n",
    "    Doctests\n",
    "    --------\n",
    "    #Regular Case\n",
    "    >>> getPages('http://www.britishmuseum.org/research/collection_online/search.aspx?searchText=augustus')\n",
    "    (1, 474)\n",
    "    \n",
    "    #Only one results page\n",
    "    >>> getPages('http://www.britishmuseum.org/research/collection_online/search.aspx?searchText=1855,0512.40')\n",
    "    (1, 1)\n",
    "    '''\n",
    "    #get page and convert to web.Element object\n",
    "    html = requests.get(url).text\n",
    "    dom = web.Element(html)\n",
    "    \n",
    "    #finds the list of pages and returns (1, 1) if no list of pages present\n",
    "    elem = dom.by_class('colSearchPaging')\n",
    "    if len(elem) < 1:\n",
    "        return (1, 1)\n",
    "    else:\n",
    "        pages = elem[0].children\n",
    "    \n",
    "    #gets the last page number of the pages list\n",
    "    last_page = pages[-4].children[0].content\n",
    "    \n",
    "    return (1, int(last_page))\n",
    "    \n",
    "#doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getLinks(url):\n",
    "    '''\n",
    "    Function\n",
    "    --------\n",
    "    Gets the urls to the objects from results page\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    url: str\n",
    "        Search page of British Museum website\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    A list of str that contain the links of the objects\n",
    "    \n",
    "    Doctest\n",
    "    -------\n",
    "    >>> getLinks('http://www.britishmuseum.org/research/collection_online/search.aspx?searchText=1855,0512.40')\n",
    "    [u'http://www.britishmuseum.org/research/collection_online/collection_object_details.aspx?objectId=1128207&partId=1&searchText=1855%2c0512.40&page=1', u'http://www.britishmuseum.org/research/collection_online/collection_object_details.aspx?objectId=3629209&partId=1&searchText=1855%2c0512.40&page=1']\n",
    "    '''\n",
    "    links = []\n",
    "    \n",
    "    #get page and convert to web.Element object\n",
    "    html = requests.get(url).text\n",
    "    dom = web.Element(html)\n",
    "    \n",
    "    #create list of row objects\n",
    "    rows = dom.by_class('grid_12 alpha row colResults')\n",
    "    \n",
    "    #traverse each row and get the links\n",
    "    for row in rows:\n",
    "        objects = row.by_class('noImage') + row.by_class('image')\n",
    "        for obj in objects:\n",
    "            link_identifier_with_noise = obj.attr['href'].split('/')[-1]\n",
    "            link_identifier = link_identifier_with_noise[5:]\n",
    "            link = 'http://www.britishmuseum.org/research/collection_online/' + link_identifier\n",
    "            links.append(link)\n",
    "    \n",
    "    return links\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDetails(url):\n",
    "    '''\n",
    "    Function\n",
    "    --------\n",
    "    Reads the data off of the given British Museum item page and puts into a dictionary\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    url: str\n",
    "        The url of the British Museum item page\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary with of result under 'result' key if reached page, else puts url under\n",
    "    'skipped' key\n",
    "    '''\n",
    "    result = {}\n",
    "    skipped = ''\n",
    "    #create list of descriptors\n",
    "    descriptors = {'Museum number', 'Denomination', 'Description', 'State', \n",
    "                 'Authority', 'Culture/period', 'Date', 'Materials', \n",
    "                  'Production place', 'Curator\\'s comments', 'Bibliography', \n",
    "                  'Subjects', 'Associated names', 'Object type', 'Weight'}\n",
    "    \n",
    "    #get page and convert to web.Element object\n",
    "    html = requests.get(url).text\n",
    "    dom = web.Element(html)\n",
    "    \n",
    "    #gets portion of page containing discription\n",
    "    try:\n",
    "        details = dom.by_class('objectDetails')[0].children\n",
    "    except:\n",
    "        details = []\n",
    "        skipped = url\n",
    "    \n",
    "    #iterate over and populate the result dictionary\n",
    "    for detail in details:\n",
    "        detail = list(BeautifulSoup(str(detail), 'html.parser').stripped_strings)\n",
    "        #print(detail)\n",
    "        if len(detail) > 1:\n",
    "            desc = detail[0]\n",
    "            if desc in descriptors:\n",
    "                result[desc] = detail[1]\n",
    "            elif desc == 'Dimensions':\n",
    "                for dim in detail[1:]:\n",
    "                    split_dim = dim.split(': ')\n",
    "                    try: \n",
    "                        if split_dim[0] in 'Weight':\n",
    "                            result['Weight (g)'] = re.findall(\"\\d+\\.\\d+\", split_dim[1])[0]\n",
    "                    except:\n",
    "                        pass\n",
    "            elif desc == 'Inscriptions':\n",
    "                inscriptions = []\n",
    "                i = 1\n",
    "                inscription = {}\n",
    "                while i < len(detail):\n",
    "                    if 'Inscription ' in detail[i]:\n",
    "                        if detail[i] == 'Inscription Type':\n",
    "                            if inscription != {}:\n",
    "                                inscriptions.append(inscription)\n",
    "                            inscription = {}\n",
    "                        descriptor = detail[i]\n",
    "                        i += 1\n",
    "                        description = detail[i]\n",
    "                        i += 1\n",
    "                        try:\n",
    "                            while 'Inscription ' not in detail[i]:\n",
    "                                description += ' ' + detail[i]\n",
    "                                i += 1\n",
    "                        except:\n",
    "                            pass\n",
    "                        inscription[descriptor] = description\n",
    "                    else:\n",
    "                        i += 1\n",
    "                result[desc] = inscriptions\n",
    "            \n",
    "    return {'result': result, 'skipped': skipped}\n",
    "              \n",
    "              \n",
    "#getDetails('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://www.britishmuseum.org/research/collection_online/search.aspx?searchText=augustus&lookup-people=e.g.+Hokusai%2C+Ramesses&people=&lookup-place=e.g.+India%2C+Shanghai%2C+Thebes&place=&from=bc&fromDate=44&to=ad&toDate=14&lookup-object=coins&object=&lookup-subject=e.g.+farming%2C+New+Testament&subject=&lookup-matcult=e.g.+Choson+Dynasty%2C+Ptolemaic&matcult=&lookup-technique=e.g.+carved%2C+celadon-glazed&technique=&lookup-school=e.g.+French%2C+Mughal+Style&school=&lookup-material=e.g.+canvas%2C+porcelain%2C+silk&material=&lookup-ethname=e.g.+Hmong%2C+Maori%2C+Tai&ethname=&lookup-ware=e.g.+Imari+ware%2C+Qingbai+ware&ware=&lookup-escape=e.g.+cylinder%2C+gravity%2C+lever&escape=&lookup-bibliography=&bibliography=&citation=&museumno=&catalogueOnly=&view='\n",
    "url = url + '&page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages = getPages(url)\n",
    "links = [getLinks(url + str(i)) for i in range(1, pages[1]+1)]\n",
    "links = [item for sublist in links for item in sublist]\n",
    "data = [getDetails(link) for link in links]\n",
    "details = []\n",
    "for datum in data:\n",
    "    details.append(datum['result'])\n",
    "    skipped = datum['skipped']\n",
    "    while skipped:\n",
    "        result = getDetails(skipped)\n",
    "        if result['result']:\n",
    "            details.append(result['result'])\n",
    "            skipped = ''\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3298"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(details)\n",
    "df.to_csv('AugustusCoins_44BC-14AD.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
